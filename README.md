Hangman AI â€” HMM + DQN Hybrid Agent
ğŸ“˜ Overview

This project implements an intelligent Hangman-playing agent that combines Hidden Markov Models (HMM) and Deep Q-Networks (DQN) for optimal letter prediction.
It demonstrates a hybrid AI system that merges probabilistic modeling with reinforcement learning to improve the success rate on unseen words.

âš™ï¸ Features

ğŸ§© HMM-based language model for probabilistic letter prediction

ğŸ¤– DQN-based reinforcement agent for dynamic decision-making

ğŸ¯ Reward shaping to encourage progress and discourage repeated/wrong guesses

ğŸ” Epsilon-greedy exploration with adaptive decay

ğŸ“Š Comprehensive evaluation on 2000-word test set

ğŸš€ Setup & Execution
1ï¸âƒ£ Install Dependencies
pip install numpy torch tqdm matplotlib reportlab

2ï¸âƒ£ Run the Notebook

Open ML_hackathon_final.ipynb in Jupyter Notebook or Google Colab.

3ï¸âƒ£ Upload Corpus

When prompted, upload a large English text file, such as:

corpus.txt


Preferably containing around 50,000 words for meaningful HMM statistics.

4ï¸âƒ£ Train the Model

Run all notebook cells sequentially until training completes.
The training combines HMM priors with DQN learning, optimizing letter prediction and reducing wrong guesses.

5ï¸âƒ£ Evaluate the Model

After training, run the final evaluation cell:

final_results = evaluate_agent(agent, test_words, num_games=2000)

6ï¸âƒ£ Test a Single Word (Demo)

You can demo the trained agent on a custom word:

play_single_game(agent, "elephant")

ğŸ§  Project Summary

This project demonstrates that combining language modeling (HMM) with reinforcement learning (DQN) creates a more powerful Hangman agent.
The HMM provides structure and priors, while the DQN learns adaptively through experience.
Together, they form a hybrid AI system capable of balancing exploration, exploitation, and linguistic intuition.
